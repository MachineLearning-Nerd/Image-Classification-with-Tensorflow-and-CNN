{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\net work\\documents\\dheeraj v\\assessment 2\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\net work\\documents\\dheeraj v\\assessment 2\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\net work\\documents\\dheeraj v\\assessment 2\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\net work\\documents\\dheeraj v\\assessment 2\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\net work\\documents\\dheeraj v\\assessment 2\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\net work\\documents\\dheeraj v\\assessment 2\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\net work\\documents\\dheeraj v\\assessment 2\\.venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\net work\\documents\\dheeraj v\\assessment 2\\.venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\net work\\documents\\dheeraj v\\assessment 2\\.venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\net work\\documents\\dheeraj v\\assessment 2\\.venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\net work\\documents\\dheeraj v\\assessment 2\\.venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\net work\\documents\\dheeraj v\\assessment 2\\.venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run on GPU\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images\\\\batches.meta', 'images\\\\data_batch_1', 'images\\\\data_batch_2', 'images\\\\data_batch_3', 'images\\\\data_batch_4', 'images\\\\data_batch_5']\n",
      "images\\batches.meta\n",
      "{b'num_cases_per_batch': 10000, b'label_names': [b'airplane', b'automobile', b'bird', b'cat', b'deer', b'dog', b'frog', b'horse', b'ship', b'truck'], b'num_vis': 3072}\n",
      "images\\data_batch_1\n",
      "images\\data_batch_2\n",
      "images\\data_batch_3\n",
      "images\\data_batch_4\n",
      "images\\data_batch_5\n"
     ]
    }
   ],
   "source": [
    "# Fetch all the files from the image folder\n",
    "files = glob.glob('images/**')\n",
    "print(files)\n",
    "dictval={}\n",
    "i = 0\n",
    "\n",
    "# Iterate over every file and try to save data to the dictval\n",
    "for file in files:\n",
    "    print(file)\n",
    "    if \"batches.meta\" in file:\n",
    "        # batches.meta contains the data for the label names \n",
    "        # and size of the batch\n",
    "        with open(file,'rb') as fo:\n",
    "            data = pickle.load(fo, encoding='bytes')\n",
    "            print(data)\n",
    "    else:\n",
    "        with open(file, 'rb') as fo:\n",
    "            temp = pickle.load(fo, encoding='bytes')\n",
    "            #print(temp)\n",
    "            if i == 0:\n",
    "                dictval['data']= list(temp[b'data'])\n",
    "                dictval['labels']= list(temp[b'labels'])\n",
    "            else:\n",
    "                dictval['data'] = dictval['data'] + list(temp[b'data'])\n",
    "                dictval['labels'] = dictval['labels'] + list(temp[b'labels'])\n",
    "            i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'airplane', b'automobile', b'bird', b'cat', b'deer', b'dog', b'frog', b'horse', b'ship', b'truck']\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "# Convert the bytes to the normal string\n",
    "print(data[b'label_names'])\n",
    "labels = [x.decode('utf-8') for x in data[b'label_names']] \n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "alldata = dictval['data']\n",
    "alldatalabels = dictval['labels']\n",
    "trainingdata = []\n",
    "def create_training_data():\n",
    "    def reshapedata(imdata, imlabel):\n",
    "        print(len(imdata))\n",
    "        for i  in range(0,len(imdata)):\n",
    "        #for i  in range(1,5):\n",
    "            # This data is the in the format of 3072 array elements\n",
    "            temp = imdata[i]\n",
    "            #print(temp)\n",
    "            #print(len(temp))\n",
    "            \n",
    "            # To reshape the data\n",
    "            img = np.reshape(temp, (3, 32,32)).T\n",
    "            #print(img.shape)\n",
    "            \n",
    "            # Convert the numpy array into the RGB format\n",
    "            img = Image.fromarray(img, 'RGB')\n",
    "            \n",
    "            # To see the image without correct orientation\n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "            \n",
    "            # img is in rotated format, so we need to rotate the image\n",
    "            # to get the original orientation\n",
    "            img = img.rotate(270)\n",
    "            \n",
    "            # Here gray conversion is done: in our application color images are not need because we \n",
    "            # can get the same information in the gray image. \n",
    "            # Benefit of using gray image : It will reduce the calculations by 3(RGB have 3 channels)\n",
    "            img  = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)\n",
    "            \n",
    "            # Just to make sure that every image is 32*32\n",
    "            img = cv2.resize(img, (32,32))\n",
    "            \n",
    "            # To see the image in the correct orientation\n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "            \n",
    "            # Just to verify that every label is int\n",
    "            if type(imlabel[i]) != type(2):\n",
    "                continue\n",
    "                \n",
    "            # Stored the labels in another variable\n",
    "            class_num = imlabel[i]\n",
    "            \n",
    "            #print(labels[class_num])\n",
    "            \n",
    "            # To create training data: \n",
    "            # I have appened the image data and the label\n",
    "            # temp[0]: This is image\n",
    "            # temp[1]: This is label\n",
    "            temp  = [img, class_num]\n",
    "            trainingdata.append(temp)\n",
    "            #break\n",
    "    reshapedata(alldata, alldatalabels)\n",
    "create_training_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to make the data shuffled randomly\n",
    "import random\n",
    "random.shuffle(trainingdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 6\n",
      "label = 3\n",
      "label = 7\n",
      "label = 5\n",
      "label = 5\n",
      "label = 5\n",
      "label = 5\n",
      "label = 1\n",
      "label = 2\n",
      "label = 9\n",
      "(50000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# This is just to check whether every data is \n",
    "# append correctly or not.\n",
    "for sample in trainingdata[:10]:\n",
    "    print(\"label = %d\" %sample[1])\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "# This is to store all the images in X\n",
    "# and all the labels in Y\n",
    "for features, label in trainingdata:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "# To reshape informat of tensorflow\n",
    "X = np.array(X).reshape(-1,32, 32, 1)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pickle.load(open(\"X.pickle\", 'rb'))\n",
    "#Y = pickle.load(open(\"Y.pickle\", 'rb'))\n",
    "\n",
    "# to normalize the data. \n",
    "X = X/255.0\n",
    "\n",
    "# 60% Training data\n",
    "x_train = X[:30000]\n",
    "y_train = Y[:30000]\n",
    "\n",
    "# 20% Testing data\n",
    "x_test = X[30000:40000]\n",
    "y_test = Y[30000:40000]\n",
    "\n",
    "# 20% Validation data\n",
    "x_val = X[40000:50000]\n",
    "y_val = Y[40000:50000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\net work\\documents\\dheeraj v\\assessment 2\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Model initialization \n",
    "model = Sequential()\n",
    "model.add(Conv2D(256, (3,3), input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(32,(3,3), input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(30))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(20))\n",
    "model.add(Activation(\"relu\"))\n",
    "# Output layers\n",
    "model.add(Dense(10))\n",
    "# Here we will get the outputs in probability \n",
    "model.add(Activation(\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 31s 1ms/sample - loss: 2.0049 - acc: 0.2634 - val_loss: 1.7716 - val_acc: 0.3694\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 28s 949us/sample - loss: 1.5715 - acc: 0.4336 - val_loss: 1.4437 - val_acc: 0.4923\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 29s 951us/sample - loss: 1.2896 - acc: 0.5369 - val_loss: 1.2715 - val_acc: 0.5569\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 28s 941us/sample - loss: 1.0989 - acc: 0.6108 - val_loss: 1.2295 - val_acc: 0.5804\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 28s 941us/sample - loss: 0.9171 - acc: 0.6777 - val_loss: 1.2164 - val_acc: 0.5871\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 28s 938us/sample - loss: 0.7053 - acc: 0.7532 - val_loss: 1.3722 - val_acc: 0.5761\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 28s 937us/sample - loss: 0.5129 - acc: 0.8205 - val_loss: 1.5649 - val_acc: 0.5678\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 28s 938us/sample - loss: 0.3520 - acc: 0.8785 - val_loss: 1.9197 - val_acc: 0.5626\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 28s 946us/sample - loss: 0.2432 - acc: 0.9179 - val_loss: 2.2871 - val_acc: 0.5474\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 28s 941us/sample - loss: 0.1720 - acc: 0.9425 - val_loss: 2.5947 - val_acc: 0.5338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23f34da16a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model compilation is done\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "# Here we are going to train the model\n",
    "model.fit(x_train, y_train,batch_size=100, validation_data=(x_val, y_val), epochs = 10)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 546us/sample - loss: 2.5740 - acc: 0.5354\n"
     ]
    }
   ],
   "source": [
    "# To find the test accuracy\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\net work\\documents\\dheeraj v\\assessment 2\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From d:\\net work\\documents\\dheeraj v\\assessment 2\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model.save('ourmodel.h5')\n",
    "saved_model = tf.keras.models.load_model('ourmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = saved_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4267510e-05 2.0714776e-06 6.5638151e-06 9.7470377e-08 9.2137447e-03\n",
      " 3.7651032e-06 4.1262282e-11 9.9074990e-01 2.5082119e-08 9.5169353e-06]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6461\n"
     ]
    }
   ],
   "source": [
    "predval = 105\n",
    "count = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if np.argmax(y_pred[i]) == y_test[i]:\n",
    "        count +=1\n",
    "accuracy = count/len(y_pred)\n",
    "print(accuracy)\n",
    "# print(np.argmax(y_pred[predval]))\n",
    "# print(y_test[predval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
